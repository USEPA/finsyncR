NRSA_inverts <- NRSA_inverts %>%
dplyr::mutate(TOTAL = round(((TOTAL / PCTCOUNT) / NUMTRANS) * 10.76, 4))
}
##Second step:
##Rarefy samples to 300 in the same manner as the NAQWA data for consistency
if(isTRUE(rarefy)) {
set.seed(seed)
NRSA_inverts <- NRSA_inverts %>%
##Create unique grouping based on UID, SITE_ID, YEAR, and VISIT_NO
##Group by this column
##Take the total individuals counted, remove those that are less than 300
tidyr::unite(Unique, c(UID, SITE_ID, YEAR, VISIT_NO), sep = "_", remove = F) %>%
dplyr::group_by(Unique) %>%
dplyr::mutate(indcounted = sum(TOTAL)) %>%
dplyr::filter(indcounted > 299) %>%
dplyr::select(-indcounted) %>%
dplyr::ungroup() %>%
##Again group by the unique sample column
##Replicate each unique sample and target taxon by the number of individuals
## found in the sample, then take 300 random individuals from these samples
dplyr::group_by(Unique, TARGET_TAXON) %>%
dplyr::slice(rep(1:dplyr::n(), times=TOTAL)) %>%
dplyr::ungroup() %>%
dplyr::group_by(Unique) %>%
dplyr::sample_n(size = 300) %>%
dplyr::group_by(Unique, TARGET_TAXON) %>%
dplyr::mutate(TOTAL = dplyr::n()) %>%
dplyr::slice(1) %>%
dplyr::ungroup() %>%
dplyr::select(-Unique)
} else {}
##Third step:
##FIX ALL TAXONOMIC ISSUES; only needed IF taxonLevel = "Genus"
##NEED TO UPDATE THIS FOR FAMILY
##Convert those genera that need to be updated
NRSA_inverts$GENUS <- ifelse(NRSA_inverts$GENUS %in% StreamData:::.switch1to1$BenchGenus,
StreamData:::.switch1to1$Genus,
NRSA_inverts$GENUS)
##This is the same code as the NAWQA taxonomy fix
if(taxonFix == "none"){
} else if(taxonFix == "lump"){
#If genera that are one of genera in dat1, rename the Genus with the slash
#label from dat1, else, keep the original Genus label
NRSA_inverts$GENUS <- ifelse(NRSA_inverts$GENUS %in% dat1$Genus,
dat1$Slash[match(NRSA_inverts$GENUS,
dat1$Genus)],
NRSA_inverts$GENUS)
#If genera that are one of problem slash genera, rename the Genus with the lumped
#label from fix_slash, else, keep the original Genus label
NRSA_inverts$GENUS <- ifelse(NRSA_inverts$GENUS %in% fix_slash$Slash,
fix_slash$Fix[match(NRSA_inverts$GENUS,
fix_slash$Slash)],
NRSA_inverts$GENUS)
#If bench genera that are one of bench genera in clust_labels, rename the Genus with the lump label from clust_labels
#else, keep the original Genus label
NRSA_inverts$GENUS <- ifelse(NRSA_inverts$GENUS %in% slashlump$genus,
slashlump$lump[match(NRSA_inverts$GENUS,
slashlump$genus)],
NRSA_inverts$GENUS)
}else if(taxonFix == "remove"){
#filter out rows that have bench genus from problem list & no species ID
NRSA_inverts <- NRSA_inverts %>%
dplyr::filter(!(GENUS %in% StreamData:::.clust_labels$genus)) %>%
dplyr::filter(!(grepl("/", GENUS)))
}
##When "taxonLevel" isn't in all caps (in the function), create a NRSA specific
##taxonLevel that is in all caps
taxonLevel.nrsa <- base::toupper(taxonLevel)
if(isTRUE(sharedTaxa)){
##List of NAWQA Genera
NAWQAgenera <- unique(TotalRows$Genus)
##List of NRSA Genera
NRSAgenera <- unique(NRSA_inverts$GENUS)
##Filter NRSA to only those genera in NAWQA
NRSA_inverts <- NRSA_inverts %>%
filter(GENUS %in% NAWQAgenera)
##Select only those taxa that appear in NAWQA
##add "tax_" prefix to the names, as this is how the genera names appear
##as columns in the NAWQA dataset
NAWQAgeneraONLY <- paste("tax_",
NAWQAgenera[!(NAWQAgenera %in% NRSAgenera)],
sep = "")
##Filter NAWQA to only those genera in NRSA (-select [delete] any that
##appear in columns in the invert_comms1 dataset)
invert_comms1 <- invert_comms1 %>%
dplyr::select(-tidyselect::any_of(NAWQAgeneraONLY))
} else {}
##Fourth step: (can get code from the getInvertData function)
## NOTE: this step is only needed when looking at taxonomic resolutions ABOVE genus
##Join all Target_taxon within each UID (sample)
##UPDATE THIS FOR NRSA_MYCOLS
mycols = c("TARGET_TAXON",
"PHYLUM",
"CLASS",
"ORDER",
"FAMILY")
nrsa_comms1 = NRSA_inverts %>%
dplyr::filter_at(dplyr::vars(tidyselect::all_of(taxonLevel.nrsa)), dplyr::any_vars(. != "")) %>%
tidyr::unite(UNIQUEID, c(UID, SITE_ID, YEAR, VISIT_NO, all_of(taxonLevel.nrsa)),
sep = "_", remove = FALSE) %>%
dplyr::group_by(UNIQUEID) %>%
dplyr::mutate(TOTAL = sum(TOTAL)) %>%
dplyr::slice(1) %>%
dplyr::ungroup() %>%
dplyr::select(-UNIQUEID) %>%
dplyr::select(-tidyselect::any_of(mycols)) %>%
tidyr::pivot_wider(names_from = tidyselect::all_of(taxonLevel.nrsa),
names_prefix = "tax_",
values_from = TOTAL,
values_fill = 0)
##Step 6: join w/ site level data
##18/19 - MISSING RT_NRSA, will put in ""
##UID, SITE_ID, VISIT_NO, SITETYPE, DATE_COL, PSTL_CODE, LAT_DD83, LON_DD83,
##AG_ECO9, URBN_NRS18, US_L3CODE, US_L3NAME
NRSA_1819_sites <- NRSA_1819_sites %>%
dplyr::select(UID, SITE_ID, VISIT_NO, SITETYPE, DATE_COL, PSTL_CODE,
LAT_DD83, LON_DD83, AG_ECO9, URBN_NRS18,
US_L3CODE, US_L3NAME) %>%
dplyr::mutate(RT_NRSA = "",
DATE_COL = as.Date(DATE_COL, format = "%m/%d/%Y"),
VISIT_NO = as.character(VISIT_NO),
MASTER_SITEID = SITE_ID) %>%
dplyr::relocate(RT_NRSA, .before = US_L3CODE) %>%
dplyr::relocate(MASTER_SITEID, .after = SITE_ID)
##13/14
##UID, SITE_ID, VISIT_NO, SITETYPE, DATE_COL, PSTL_CODE, LAT_DD83, LON_DD83,
##AG_ECO9, NRS13_Urban, RT_NRSA, US_L3CODE, US_L3NAME,
NRSA_1314_sites <- NRSA_1314_sites %>%
dplyr::select(UID, SITE_ID, VISIT_NO, SITETYPE, DATE_COL, PSTL_CODE,
LAT_DD83, LON_DD83, AG_ECO9, NRS13_URBN, RT_NRSA,
US_L3CODE, US_L3NAME) %>%
dplyr::mutate(RT_NRSA = ifelse(RT_NRSA == "?",
"",
RT_NRSA),
DATE_COL = as.Date(DATE_COL, format = "%m/%d/%Y"),
VISIT_NO = as.character(VISIT_NO),
MASTER_SITEID = SITE_ID) %>%
dplyr::relocate(MASTER_SITEID, .after = SITE_ID)
##08/09 - MISSING L3 NAME (not a problem)
##UID, SITE_ID, VISIT_NO, SITE_CLASS, DATE_COL, STATE, LAT_DD83, LONG_DD83,
##AGGR_ECO9_2015, URBAN, RT_NRSA, US_L3CODE_2015
NRSA_0809_sites <- NRSA_0809_sites %>%
dplyr::select(UID, SITE_ID, MASTER_SITEID, VISIT_NO, SITE_CLASS, DATE_COL, STATE,
LAT_DD83, LON_DD83, AGGR_ECO9_2015, URBAN, RT_NRSA,
US_L3CODE_2015) %>%
dplyr::mutate(RT_NRSA = ifelse(RT_NRSA == "R",
"R",
ifelse(RT_NRSA == "S",
"In",
ifelse(RT_NRSA == "T",
"Im",
"")))) %>%
dplyr::mutate(US_L3NAME = "",
DATE_COL = as.Date(DATE_COL, format = "%d-%b-%y"),
VISIT_NO = as.character(VISIT_NO))
##For some reason, one MASTER_SITEID is missing for one replicate sample, so give it the site id
NRSA_0809_sites$MASTER_SITEID[which(NRSA_0809_sites$SITE_ID == "FW08LA004")] = "FW08LA004"
##03/04 - MISSING UID (will create in the same way as above), URBAN
##SITE_ID, VISIT_NO, SITETYPE, DATE_COL, STATE, LAT_DD, LON_DD,
##ECOWSA9, RT_WSA, ECO3, ECO3_NM
NRSA_0304_sites <- NRSA_0304_sites %>%
dplyr::select(SITE_ID, VISIT_NO, SITETYPE, DATE_COL, STATE, LAT_DD, LON_DD,
ECOWSA9, RT_WSA, ECO3, ECO3_NM) %>%
dplyr::mutate(RT_WSA = ifelse(RT_WSA == "R",
"R",
ifelse(RT_WSA == "S",
"In",
ifelse(RT_WSA == "T",
"Im",
"")))) %>%
dplyr::mutate(URBAN = "",
UID = paste("200304", SITE_ID, VISIT_NO,
sep = "_"),
DATE_COL = as.Date(DATE_COL, format = "%m/%d/%Y"),
VISIT_NO = as.character(VISIT_NO),
MASTER_SITEID = SITE_ID) %>%
dplyr::relocate(UID, .before = SITE_ID) %>%
dplyr::relocate(URBAN, .before = RT_WSA) %>%
dplyr::relocate(MASTER_SITEID, .after = SITE_ID)
##Set all column names equal to each other
colnames(NRSA_0304_sites) =
colnames(NRSA_0809_sites) =
colnames(NRSA_1819_sites) =
colnames(NRSA_1314_sites)
NRSA_sites <-  dplyr::bind_rows(list(NRSA_1819_sites, NRSA_1314_sites,
NRSA_0809_sites, NRSA_0304_sites))
NRSA_sites$YEAR = lubridate::year(NRSA_sites$DATE_COL)
##Join with nrsa_comms1 to get site-level data
nrsa_comms1 = nrsa_comms1 %>%
tidyr::unite(UNIQUEID, c(UID, SITE_ID, YEAR, VISIT_NO),
sep = "_", remove = FALSE) %>%
dplyr::left_join(NRSA_sites %>%
tidyr::unite(UNIQUEID, c(UID, SITE_ID, YEAR, VISIT_NO),
sep = "_", remove = T), by = "UNIQUEID") %>%
dplyr::relocate(tidyselect::contains("tax_"), .after = last_col()) %>%
dplyr::mutate(ProjectLabel = ifelse(YEAR %in% c(2013, 2014),
"NRSA1314",
ifelse(YEAR %in% c(2008, 2009),
"NRSA0809",
ifelse(YEAR %in% c(2018, 2019),
"NRSA1819",
"WSA"))),
ProjectAssignedSampleLabel = UID,
NAWQA.SMCOD = UNIQUEID,
NAWQAStudyUnitCode = SITETYPE,
CollectionDate = DATE_COL,
StartTime = NA,
TimeDatum = NA,
CollectionYear = YEAR,
CollectionMonth = lubridate::month(DATE_COL),
CollectionDayOfYear = lubridate::yday(DATE_COL),
SiteVisitSampleNumber = VISIT_NO,
ProvisionalData = NA,
SiteNumber = MASTER_SITEID,
SiteName = MASTER_SITEID,
StateFIPSCode = NA,
CountyFIPSCode = NA,
Latitude_dd = LAT_DD83,
Longitude_dd = LON_DD83,
CoordinateDatum = "NAD83",
HUCCode = NA,
DrainageArea_mi2 = NA ,
SampleTypeCode = SAMPLE_TYPE,
IdentificationEntity = NA,
AreaSampTot_m2  = NA,
GeomorphicChannelUnit = NA,
ChannelBoundaries = NA,
ChannelFeatures = NA,
ReplicateType  = NA,
FieldSplitRatio = NA,
LabSubsamplingRatio = NA,
PropID = PCTCOUNT,
AreaSampTot_m2 = round(NUMTRANS / 10.76, 3)
) %>%
dplyr::select(-SAMPLE_TYPE, -LAT_DD83, -LON_DD83, -SITETYPE,
-SITE_ID, -MASTER_SITEID, -UID, -UNIQUEID, -DATE_COL,
-YEAR, -PSTL_CODE, -US_L3CODE, -US_L3NAME, -VISIT_NO,
-AG_ECO9, -NRS13_URBN, -RT_NRSA, -PCTCOUNT, -NUMTRANS) %>%
dplyr::relocate(tidyselect::contains("tax_"), .after = last_col())
##To make sure the NRSA sites are correct crosswalked across sampling rounds
# rename the nrsa_comms1$SiteNumber based on the master crosswalk list from
# Richard Mitchell (w/ updates to include MASTER_SITEID)
##if site number in nrsa_comms1 is in the SITEID in the master crosswalk list,
##match the numbers and pull the corresponding unique id, which is the crosswalked site id,
##else provide an NA
nrsa_comms1$UNIQUE_ID <- ifelse(nrsa_comms1$SiteNumber %in% StreamData:::.NRSA_siteIDs$SITE_ID,
StreamData:::.NRSA_siteIDs$UNIQUE_ID[match(nrsa_comms1$SiteNumber,
StreamData:::.NRSA_siteIDs$SITE_ID)],
NA)
##if site number in nrsa_comms1 is in the MASTER_SITEID in the master crosswalk list,
##match the numbers and pull the corresponding unique id, which is the crosswalked site id,
##else give the current UNIQUE ID
nrsa_comms1$UNIQUE_ID <- ifelse(nrsa_comms1$SiteNumber %in% StreamData:::.NRSA_siteIDs$MASTER_SITEID,
StreamData:::.NRSA_siteIDs$UNIQUE_ID[match(nrsa_comms1$SiteNumber,
StreamData:::.NRSA_siteIDs$MASTER_SITEID)],
nrsa_comms1$UNIQUE_ID)
##if there are any NA values in UNIQUE ID, replace these with the SiteNumber
nrsa_comms1$SiteNumber = ifelse(is.na(nrsa_comms1$UNIQUE_ID),
nrsa_comms1$SiteNumber,
nrsa_comms1$UNIQUE_ID)
##remove the UNIQUEID column, as it is no longer needed
nrsa_comms1 <- nrsa_comms1 %>%
select(-UNIQUE_ID)
##Need to then join this dataset to invert_comms1
invert_comms1[setdiff(names(nrsa_comms1), names(invert_comms1))] <- NA
nrsa_comms1[setdiff(names(invert_comms1), names(nrsa_comms1))] <- NA
##Add Agency columns
invert_comms1$Agency <- "USGS"
nrsa_comms1$Agency <- "EPA"
invert_comms1 <- invert_comms1  %>%
dplyr::relocate(tidyselect::contains("tax_"), .after = last_col())
nrsa_comms1 <- nrsa_comms1  %>%
dplyr::relocate(tidyselect::contains("tax_"), .after = last_col()) %>%
dplyr::relocate(tidyselect::any_of(colnames(invert_comms1)))
invert_comms1 <- dplyr::bind_rows(invert_comms1, nrsa_comms1)
invert_comms1 = invert_comms1 %>%
dplyr::mutate(dplyr::across(tidyselect::starts_with("tax_"),
~ifelse(is.na(.x),
0,
.x)))
} else{ }
if(dataType == "occur") {
invert_comms1 = invert_comms1 %>%
dplyr::mutate(dplyr::across(tidyselect::starts_with("tax_"),
~replace(., . > 0, 1)))
}
invert_comms1$CollectionDate = as.Date(invert_comms1$CollectionDayOfYear,
origin = paste(invert_comms1$CollectionYear-1,
'12-31',
sep = "-"))
##Remove the "tax_" prefix
colnames(invert_comms1) = sub("tax_", "", colnames(invert_comms1))
return(data.frame(invert_comms1))
}
datInv <- getInvertData(dataType = "abun",
taxonLevel = "Genus",
taxonFix = "lump",
agency = c("USGS", "EPA"),
lifestage = FALSE,
rarefy = FALSE,
sharedTaxa = TRUE,
seed = 0)
traceback()
library(StreamData)
datInv <- getInvertData(dataType = "abun",
taxonLevel = "Genus",
taxonFix = "lump",
agency = c("USGS", "EPA"),
lifestage = FALSE,
rarefy = FALSE,
sharedTaxa = TRUE,
seed = 0)
inverts_NAWQA_sites <- datInv %>%
dplyr::select(SiteNumber, CollectionYear) %>%
group_by(SiteNumber, CollectionYear) %>%
slice(1) %>%
ungroup()
library(tidyverse)
inverts_NAWQA_sites <- datInv %>%
dplyr::select(SiteNumber, CollectionYear) %>%
group_by(SiteNumber, CollectionYear) %>%
slice(1) %>%
ungroup()
data = inverts_NAWQA_sites
scale = "Cat"
group = F
##Read in NLCD data from streamcat dataset from Ryan Hill
streamcat <- read.csv(base::system.file("extdata",
"streamcat_all.csv",
package = "StreamData"))
##Focus on only those that end in Cat (catchment) or Ws (watershed)
cat_ws_cols <- colnames(streamcat)[stringr::str_sub(colnames(streamcat), -3) == "Cat" |
stringr::str_sub(colnames(streamcat), -2) == "Ws"]
streamcat2 = streamcat %>%
##Select columns that are pertinent: site info, size of Ws/Cat, and above cols
dplyr::select(COMID, SiteNumber, CatAreaSqKm, WsAreaSqKm, all_of(cat_ws_cols)) %>%
##Pivot longer, so that non-site info columns are in "Info" and the values are
##in "value"; this will help with extraction of year and scale information
##In turn, this process will make it easier to join StreamCat data w/ biodata
tidyr::pivot_longer(cols = tidyselect::ends_with("Cat") |
tidyselect::ends_with("Ws") |
tidyselect::starts_with("Cat") |
tidyselect::starts_with("Ws"),
names_to = "Info"
) %>%
##Get info on whether it is for the Ws or Cat, whether the column has specific
##values for each year (NLCD);
##Extract what the data is (Info2): i.e. PctUrb, PctCrop, etc.
##From this, provide broad groupings for NLCD data:
## Urb, Crop, and Hay are HumanDominated; everything else is "Natural"
dplyr::mutate(Scale = ifelse(grepl("Cat", Info),
"Cat",
"Ws"),
Y_spec = ifelse(grepl("20", Info),
"Y",
"N"),
Year = ifelse(Scale == "Cat" & Y_spec == "Y",
stringr::str_sub(Info, -7, -4),
ifelse(Scale == "Ws" & Y_spec == "Y",
stringr::str_sub(Info, -6, -3),
NA
)),
Info2 = ifelse(is.na(Year),
stringr::str_remove(Info, scale),
stringr::str_remove(stringr::str_remove(Info, scale), Year))
) %>%
dplyr::filter(Scale %in% scale) %>%
dplyr::filter(Info2 %in% c("PctBl", "PctConif", "PctCrop", "PctDecid", "PctGrs",
"PctHay", "PctHbWet", "PctMxFst", "PctOw", "PctShrb",
"PctUrbHi", "PctUrbLo", "PctUrbMd", "PctUrbOp",
"PctWdWet")) %>%
##Remove columns we no longer need
dplyr::select(-Y_spec, -Info)
##Join Area of Ws and Cat with LULC data
USGS_streamcat <- streamcat2 %>%
tidyr::unite(InfoBroadScale, c("Info2", "Scale"), sep = "_", remove = T) %>%
tidyr::pivot_wider(id_cols = c("COMID", "SiteNumber", "Year"),
names_from = "InfoBroadScale",
values_from = "value") %>%
dplyr::mutate(Year = as.numeric(Year))
View(streamcat2)
streamcat2 %>%
tidyr::unite(InfoBroadScale, c("Info2", "Scale"), sep = "_", remove = T)
streamcat2 %>%
tidyr::unite(InfoBroadScale, c("Info2", "Scale"), sep = "_", remove = T) %>%
group_by(COMID, SiteNumber, Year, InfoBroadScale) %>%
summarize(count = n())
datig <- streamcat2 %>%
tidyr::unite(InfoBroadScale, c("Info2", "Scale"), sep = "_", remove = T) %>%
group_by(COMID, SiteNumber, Year, InfoBroadScale) %>%
summarize(count = n())
View(datig)
datig <- streamcat2 %>%
tidyr::unite(InfoBroadScale, c("Info2", "Scale"), sep = "_", remove = T) %>%
group_by(COMID, SiteNumber, Year, InfoBroadScale) %>%
summarize(count = n()) %>%
filter(count > 1) %>%
group_by(SiteNumber) %>%
slice(1)
View(datig)
streamcat2 %>%
filter(SiteNumber %in% datig$SiteNumber)
View(streamcat2 %>%
filter(SiteNumber %in% datig$SiteNumber))
streamcat <- read.csv("./inst/extdata/streamcat_all.csv")
streamcat
View(streamcat)
streamcat_n <- streamcat %>%
group_by(COMID, SiteNumber) %>%
slice(1)
nrow(streamcat); nrow(streamcat_n)
streamcat <- streamcat_n
##Focus on only those that end in Cat (catchment) or Ws (watershed)
cat_ws_cols <- colnames(streamcat)[stringr::str_sub(colnames(streamcat), -3) == "Cat" |
stringr::str_sub(colnames(streamcat), -2) == "Ws"]
streamcat2 = streamcat %>%
##Select columns that are pertinent: site info, size of Ws/Cat, and above cols
dplyr::select(COMID, SiteNumber, CatAreaSqKm, WsAreaSqKm, all_of(cat_ws_cols)) %>%
##Pivot longer, so that non-site info columns are in "Info" and the values are
##in "value"; this will help with extraction of year and scale information
##In turn, this process will make it easier to join StreamCat data w/ biodata
tidyr::pivot_longer(cols = tidyselect::ends_with("Cat") |
tidyselect::ends_with("Ws") |
tidyselect::starts_with("Cat") |
tidyselect::starts_with("Ws"),
names_to = "Info"
) %>%
##Get info on whether it is for the Ws or Cat, whether the column has specific
##values for each year (NLCD);
##Extract what the data is (Info2): i.e. PctUrb, PctCrop, etc.
##From this, provide broad groupings for NLCD data:
## Urb, Crop, and Hay are HumanDominated; everything else is "Natural"
dplyr::mutate(Scale = ifelse(grepl("Cat", Info),
"Cat",
"Ws"),
Y_spec = ifelse(grepl("20", Info),
"Y",
"N"),
Year = ifelse(Scale == "Cat" & Y_spec == "Y",
stringr::str_sub(Info, -7, -4),
ifelse(Scale == "Ws" & Y_spec == "Y",
stringr::str_sub(Info, -6, -3),
NA
)),
Info2 = ifelse(is.na(Year),
stringr::str_remove(Info, scale),
stringr::str_remove(stringr::str_remove(Info, scale), Year))
) %>%
dplyr::filter(Scale %in% scale) %>%
dplyr::filter(Info2 %in% c("PctBl", "PctConif", "PctCrop", "PctDecid", "PctGrs",
"PctHay", "PctHbWet", "PctMxFst", "PctOw", "PctShrb",
"PctUrbHi", "PctUrbLo", "PctUrbMd", "PctUrbOp",
"PctWdWet")) %>%
##Remove columns we no longer need
dplyr::select(-Y_spec, -Info)
##Join Area of Ws and Cat with LULC data
USGS_streamcat <- streamcat2 %>%
tidyr::unite(InfoBroadScale, c("Info2", "Scale"), sep = "_", remove = T) %>%
tidyr::pivot_wider(id_cols = c("COMID", "SiteNumber", "Year"),
names_from = "InfoBroadScale",
values_from = "value") %>%
dplyr::mutate(Year = as.numeric(Year))
##Years are the NLCD years
Years = c(2001,2004,2006,2008,2011,2013,2016)
##Create a holder column to be used to match the datasets tmeporally
data$ClosestYear = 0
##Generate closest LULC year
for(i in 1:nrow(data)){
data$ClosestYear[i] = as.numeric(Years[which.min(abs(Years-data$CollectionYear[i]))])
}
##Join the datasets
data = data %>%
dplyr::left_join(USGS_streamcat,
by = c("SiteNumber" = "SiteNumber",
"ClosestYear" = "Year")) %>%
dplyr::select(-ClosestYear, -COMID)
return(data)
data
write.csv(streamcat, "./inst/extdata/streamcat_all.csv", row.names = N)
write.csv(streamcat, "./inst/extdata/streamcat_all.csv", row.names = F)
streamcat_n <- data.frame(streamcat_n)
write.csv(streamcat_n, "./inst/extdata/streamcat_all.csv", row.names = F)
streamcat_n
devtools::document()
devtools::build()
datnrsa <- read.csv("C:/Users/mikem/Downloads/bentdens_4yr.csv") %>%
filter(SAMPLE_TYPE == "BERW")%>%
filter(YEAR > 2004) %>%
mutate(PCTCOUNT = 1 / SUB_CF) %>%
dplyr::select(SITE_ID, UNIQUE_ID, YEAR, VISIT_NO, ABUNDCNT, TOTLDENS, PCTCOUNT,
TRANSECTS_SAMPLED_DENS) %>%
rename(NUMTRANS = TRANSECTS_SAMPLED_DENS)
library(tidyverse)
##Read in NRSA data, remove non-BERW samples, remove WSA samples, select columns of interest
datnrsa <- read.csv("C:/Users/mikem/Downloads/bentdens_4yr.csv") %>%
filter(SAMPLE_TYPE == "BERW")%>%
filter(YEAR > 2004) %>%
mutate(PCTCOUNT = 1 / SUB_CF) %>%
dplyr::select(SITE_ID, UNIQUE_ID, YEAR, VISIT_NO, ABUNDCNT, TOTLDENS, PCTCOUNT,
TRANSECTS_SAMPLED_DENS) %>%
rename(NUMTRANS = TRANSECTS_SAMPLED_DENS)
datnrsa
View(datnrsa)
Traits_Vieira_pp <- readRDS("~/R Package Builds/StreamData/inst/extdata/Traits_Vieira_pp.rds")
View(Traits_Vieira_pp)
devtools::build()
devtools::document()
devtools::build()
install.packages("C:/Users/mikem/Documents/R Package Builds/StreamData_0.0.0.9220.tar.gz", type = "source", repo = NULL)
library(StreamData)
detach("package:StreamData", unload = TRUE)
install.packages("C:/Users/mikem/Documents/R Package Builds/StreamData_0.0.0.9220.tar.gz", type = "source", repo = NULL)
